{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "readme-header",
   "metadata": {},
   "source": [
    "# TITAN Tutorial\n",
    "\n",
    "---\n",
    "\n",
    "<img align=\"right\" width=\"300\" height=\"300\" src=\"../images/hail_case_tracks.png\">\n",
    "\n",
    "This interactive tutorial takes you through the steps of how to run the Thunderstorm Identification, Tracking, Analysis and Nowcasting (TITAN) suite. TITAN was originally designed as an algorithm to objectively identify and track thunderstorms from weather radar data for a weather modification experiment in South Africa in the 1980s. Now, Titan includes forecasting, storm analysis, and climatological analysis. TITAN now refers to the larger system in which the original application is one component.\n",
    "\n",
    "Titan is described in more detail in [Dixon and Wiener (1993)](https://doi.org/10.1175/1520-0426(1993)010%3C0785:TTITAA%3E2.0.CO;2).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Titan Background\n",
    "\n",
    "TITAN identifies storm objects as a contiguous region of echo that exceeds a user-defined reflectivity threshold and minimum volume. Dual thresholds are used to deal with storm objects that briefly touch, but do not merge. Storm tracking is performed by looking for regions of overlap between storm objects at successive time intervals. Short term storm extrapolation forecasts are used to identify instances of storm merging and splitting. TITAN output includes storm tracks, polygons outlining the storm objects, and storm property information (e.g., volume, area, mass, precipitation flux).\n",
    "\n",
    "The high-level workflow for TITAN is shown in the graphic below. Key steps include quality controlling the data to remove any non-meteorological or compromised echoes and gridding the data to a Cartesian grid. Once TITAN is run and the tracks are produced, those data need to be converted into more user-friendly file types. \n",
    "\n",
    "<img align=\"center\" width=\"600\" src=\"../images/lrose/titan_highlevel.png\">\n",
    "\n",
    "A more detailed workflow for TITAN that includes each step, application, and data type is shown in the graphic below.\n",
    "\n",
    "<img align=\"center\" width=\"800\" src=\"../images/lrose/titan_data_flow.png\">\n",
    "\n",
    "## Tutorial Overview\n",
    "### 1. Setup\n",
    "\n",
    "#### Download raw data and prepare parameter files\n",
    "\n",
    "Raw data files that are provided:\n",
    "* A hail storm in Alberta, observed by the Strathmore radar 40 km east Calgary.\n",
    "* A derecho event in Ontario, observed by the King City radar 40 km north of Toronto.\n",
    "\n",
    "Both of these are 10 cm (S-band) Gematronik dual polarization radars.\n",
    "\n",
    "The data (as a .tgz file) has been provided in the form of a zipped tar file, which we will unzip create the following tree:\n",
    "\n",
    "```\n",
    "  ./data/ams2025/ERA5/20220521\n",
    "  ./data/ams2025/ERA5/20240806\n",
    "  ./data/ams2025/radar/raw/hail/20240806*.h5\n",
    "  ./data/ams2025/radar/raw/derecho/20220521*.h5\n",
    "```\n",
    "\n",
    "### 2. Output data\n",
    "\n",
    "After the full analysis has been run, the following derived data directories should exist:\n",
    "\n",
    "```\n",
    "  ./data/ams2025/ERA5/spdb/Strathmore/20240806* (soundings from ERA5)\n",
    "  ./data/ams2025/ERA5/spdb/KingCity/20220521* (soundings from ERA5)\n",
    "  ./data/ams2025/radar/cfradial/qc/Strathmore/20240806/cfrad.20240806*nc (cfradial after QC)\n",
    "  ./data/ams2025/radar/cfradial/qc/KingCity/20220521/cfrad.20220521*nc (cfradial after QC)\n",
    "  ./data/ams2025/radar/cfradial/pid/Strathmore/20240806/cfrad.20240806*nc (cfradial PID)\n",
    "  ./data/ams2025/radar/cfradial/pid/Strathmore/20240806/cfrad.20240806*nc (cfradial PID)\n",
    "  ./data/ams2025/radar/cart/qc/Strathmore/20240806/ncf_20240806*nc (Cartesian MDC CF-compliant netcdf)\n",
    "  ./data/ams2025/radar/cart/qc/KingCity/20220521/ncf_202205216*nc (Cartesian MDC CF-compliant netcdf)\n",
    "  ./data/ams2025/titan/storms/Strathmore/20240806* (Titan binary files)\n",
    "  ./data/ams2025/titan/storms/KingCity/20220521* (Titan binary files)\n",
    "  ./data/ams2025/titan/ascii/Tracks2Ascii.hail.txt (Titan output converted by Tracks2Ascii)\n",
    "  ./data/ams2025/titan/ascii/Tracks2Ascii.derecho.txt (Titan output converted by Tracks2Ascii)\n",
    "  ./data/ams2025/titan/netcdf/Strathmore/titan_20240806.nc (Titan output converted by Tstorms2NetCDF)\n",
    "  ./data/ams2025/titan/netcdf/KingCity/titan_20220521.nc (Titan output converted by Tstorms2NetCDF)\n",
    "```\n",
    "\n",
    "### 3. Note on task cells\n",
    "\n",
    "This notebook uses two colored cells to indicate tasks.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>File Task: modify parameters in text files.</b> \n",
    "\n",
    "These text blocks help the user modify the parameter files or other functions in *external* text files.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: run a command in Jupyter notebook cell.</b> \n",
    "\n",
    "These text blocks instruct the users to run a command *in* a cell within the Jupyter notebook. If you prefer, you are welcome to copy the commands (minus the ! symbol) into a terminal window.\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "## Environment and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-description",
   "metadata": {},
   "source": [
    "First, we import the required python packages to run this notebook. Most of the LROSE processing can be done with the os package and shell commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkout-project",
   "metadata": {},
   "source": [
    "## 1.1 Set up directories\n",
    "\n",
    "We need to set up the required data directories. The raw radar data will be grabbed from the S3 bucket. We delete any existing files and directories specific to this tutorial to ensure we're starting with clean directories and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checkout-commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make overall titan directory and application output directory\n",
    "!mkdir -p ./data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-environment",
   "metadata": {},
   "source": [
    "## 1.2 Set up the environment\n",
    "\n",
    "First, we'll set some key variables we'll need throughout the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f7501-bd19-4fd9-b750-eda6412fadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory variable to call LROSE\n",
    "os.environ[\"LROSE_DIR\"] = \"/usr/local/lrose/bin\"\n",
    "os.environ[\"DATA_DIR\"] = \"./data/ams2025\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1724c-9baf-4aba-8c48-b9fc75090bfe",
   "metadata": {},
   "source": [
    "## 1.3 Get data\n",
    "\n",
    "Because some of the preprocessing requires ancillary data, we need to grab and untar that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb68f1-0562-4711-b33a-29d14223356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://js2.jetstream-cloud.org:8001/pythia/radar/ams2025/ams2025_titan.raw.tgz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873fa68-805d-43e6-bcc3-6ec8b647a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./ams2025_titan.raw.tgz ./data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013c9ab-b143-4519-b1a4-1e8f7c81851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf ./data/ams2025_titan.raw.tgz -C ./data/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing-steps",
   "metadata": {},
   "source": [
    "# 2. Prepare data for analysis\n",
    "\n",
    "The following sections describe two quality control setups and how to run the scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-1",
   "metadata": {},
   "source": [
    "## 2.1: Option 1 - Apply quality control (QC) on the raw radar data and convert to CfRadial format using RadxConvert\n",
    "\n",
    "In the hail case, there is no significant signal interference. \n",
    "\n",
    "<img align=\"center\" width =\"600\" src=\"../images/lrose/hail.dbz.no_qc.png\">\n",
    "\n",
    "In the derecho case, considerable interference is present, appearing as radial spikes.  \n",
    "\n",
    "<img align=\"center\" width =\"600\" src=\"../images/lrose/derecho.dbz.no_qc.png\">\n",
    "\n",
    "\n",
    "Closer inspection of these spikes shows that the interference sources are not coherent with the radars, as indicated by:  \n",
    "\n",
    "* Low SQI (NCP)  \n",
    "* Moderately low SNR  \n",
    "\n",
    "To address this, we use `RadxConvert` to censor data fields based on thresholds applied to the input fields. Specifically, data are removed at gates where **both** conditions are met:  \n",
    "\n",
    "* SQI (NCP) < 0.2  \n",
    "* SNR < 25 dB  \n",
    "\n",
    "Since later QC steps require signal-to-noise ratio (SNR), the SNR field is derived from reflectivity (DBZ) and added during processing.  \n",
    "\n",
    "Finally, the raw HDF5 files are converted to CfRadial format using `RadxConvert` with this simple quality control applied.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-2-derecho",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Run QC on derecho case data.</b> \n",
    "    <br>\n",
    "    Run the derecho case QC script:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/RadxConvert -sort_rays_by_time -const_ngates -params ./params/titan/RadxConvert.qc.derecho -debug -f ${DATA_DIR}/radar/raw/derecho/202205211*CASKR.h5</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-derecho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run QC on derecho case data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fc9289-9f15-4f20-ba07-ce65dd9faa1a",
   "metadata": {},
   "source": [
    "This simple QC removes some of the bad data, as shown by the screenshots below from the derecho case.\n",
    "\n",
    "<img align=\"left\" width =\"600\" src=\"../images/lrose/derecho.dbz.no_qc.png\">\n",
    "<img align=\"left\" width =\"600\" src=\"../images/lrose/derecho.dbz.qc.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-3",
   "metadata": {},
   "source": [
    "## 2.2: Option 2 - Computing PID as an alternative method of censoring using RadxPid\n",
    "\n",
    "An alternative method for cleaning up interference is to run RadxPid, and censor non-meteorological echoes.\n",
    "\n",
    "First, we have to download the ERA5 reanalysis for these cases, and we can use that to save the model-based soundings:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Run ERA5 sounding scripts.</b> \n",
    "    <br>\n",
    "    Run the ERA5 sounding scripts:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/Mdv2SoundingSpdb -debug -params ./params/titan/Mdv2SoundingSpdb.ERA5.derecho -f $DATA_DIR/ERA5/20220521/20220521_*</code><br>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1460f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ERA5 sounding for derecho case data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1971f2",
   "metadata": {},
   "source": [
    "And we can then run RadxPid:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-3-derecho",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Run PID on derecho case data.</b> \n",
    "    <br>\n",
    "    Run the derecho case PID script:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/RadxPid -params ./params/titan/RadxPid.derecho -debug</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pid-derecho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PID on derecho case data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pid-explanation",
   "metadata": {},
   "source": [
    "The following shows the PID field for the derecho case:\n",
    "\n",
    "<img align=\"center\" width =\"600\" src=\"../images/lrose/derecho.pid.png\">\n",
    "\n",
    "The interference is identified as clutter in this case.\n",
    "\n",
    "And the following shows the raw data and after using PID to clean up the reflectivity field:\n",
    "\n",
    "<img align=\"center\" width =\"600\" src=\"../images/lrose/derecho.dbz.no_qc.png\">\n",
    "<img align=\"center\" width =\"600\" src=\"../images/lrose/derecho.dbz.censored_by_pid.png\">\n",
    "\n",
    "\n",
    "For this tutorial we will use the QC data created by RadxConvert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-4",
   "metadata": {},
   "source": [
    "## 2.3: Convert to Cartesian grid using Radx2Grid\n",
    "\n",
    "Titan requires input data in Cartesian coordinates, rather than polar.\n",
    "To perform this transformation, we run the following to convert the data to Cartesian grid format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-4-derecho",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Convert derecho case to Cartesian grid.</b> \n",
    "    <br>\n",
    "    Run the derecho case grid conversion script:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/Radx2Grid -params ./params/titan/Radx2Grid.derecho -debug</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grid-derecho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert derecho case to Cartesian grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-5",
   "metadata": {},
   "source": [
    "# 3. Run TITAN storm tracking\n",
    "\n",
    "Run the TITAN algorithm to identify and track storms.\n",
    "\n",
    "Titan runs on the Cartesian gridded data, using the DBZ field and optionally the VEL field to compute storm rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-5-derecho",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Run TITAN on derecho case data.</b> \n",
    "    <br>\n",
    "    Run the derecho case TITAN script:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/Titan -params ./params/titan/Titan.derecho -start \"2022 05 21 12 00 00\" -end \"2022 05 21 20 00 00\" -debug</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "titan-derecho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TITAN on derecho case data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-6",
   "metadata": {},
   "source": [
    "# 4. Convert TITAN binary output to readable format\n",
    "\n",
    "## 4.1 Convert TITAN binary output to ASCII format for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-6-derecho",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Convert derecho case TITAN output to ASCII.</b> \n",
    "    <br>\n",
    "    Run the derecho case ASCII conversion script:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/Titan -params ./params/titan/Titan.derecho -start \"2022 05 21 12 00 00\" -end \"2022 05 21 20 00 00\" -debug</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ascii-derecho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert derecho case TITAN output to ASCII\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-7",
   "metadata": {},
   "source": [
    "## 4.2: Convert TITAN output to NetCDF format\n",
    "\n",
    "Convert TITAN binary output to NetCDF format for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-7-derecho",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> <b>Cell Task: Convert derecho case TITAN output to NetCDF.</b> \n",
    "    <br>\n",
    "    Run the derecho case NetCDF conversion script:\n",
    "    <br>\n",
    "    <code lang=\"bash\">!$LROSE_DIR/Tstorms2NetCDF -params ./params/titan/Tstorms2NetCDF.derecho -debug -f $DATA_DIR/titan/storms/KingCity/20220521.sh5</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "netcdf-derecho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert derecho case TITAN output to NetCDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d38621",
   "metadata": {},
   "source": [
    "# 5. Plot Output\n",
    "\n",
    "We'll load the necessary Python packages and plot some of the TITAN output now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb899712-f969-483f-a332-4a020b3fc03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6431a33-6f1b-4432-8211-af35841858cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./data/titan/titan/ascii/Tracks2Ascii.derecho.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ac857-683a-442e-8f41-778099fdcd13",
   "metadata": {},
   "source": [
    "Open text file and adjust columns names in order to import to a pandas dataframe. \n",
    "Since the text file has irregular delimiters, we need to add some extra steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b7dad-46c3-4bdd-b56f-bebcad00a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file and extract column names\n",
    "f = open(file)\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "label_line_index = None  \n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if 'labels' in line:\n",
    "        label_line_index = i\n",
    "        break  \n",
    "labels = lines[label_line_index].split(\":\", 1)[1].strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670420a1-fb90-45f8-a58f-c9862f38160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data lines are the ones that do not start with #\n",
    "data_lines = [line.strip() for line in lines if not line.startswith(\"#\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c3a7f-ab3e-4515-8980-506b20388446",
   "metadata": {},
   "source": [
    "The file last three rows are labeled \"parents\",\"children\",\"nPolySidesPolygonRays*72\". Parents and children columns refer to identifiers based on merging and splitting processes. The Polygon column shows the values for the lines from the polygon centroid to each vertex, in km. There are 72 values because each line is separated 5 deg (72*5 =360). With that information and the \"envelope_centroid\" column, we can retrieve the cells envelopes at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05047e5-7a7c-42e6-8e14-7009ded77b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for line in data_lines:\n",
    "    parts = line.split()\n",
    "\n",
    "    try:\n",
    "        # Try parsing the polygon count value (always right before 72 values)\n",
    "        poly_count_index = -73  # 72 floats + 1 count (the column starts with the numnber 72, which is not part of the values)\n",
    "\n",
    "        # Parents and children may be missing\n",
    "        parent_str = parts[poly_count_index - 2]\n",
    "        child_str = parts[poly_count_index - 1]\n",
    "\n",
    "        # Handle missing values marked as \"-\"\n",
    "        parents = int(parent_str) if parent_str != '-' else np.nan\n",
    "        children = int(child_str) if child_str != '-' else np.nan\n",
    "\n",
    "        # Polygon values: skip the count, get the next 72 values\n",
    "        polygon_values = list(map(float, parts[poly_count_index + 1:]))\n",
    "\n",
    "        # Fixed columns\n",
    "        fixed_cols = parts[:poly_count_index - 2]\n",
    "\n",
    "        # Combine into one row\n",
    "        row = fixed_cols + [parents, children, polygon_values]\n",
    "        rows.append(row)\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07c49f-031a-4cc3-8c68-494811f5b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final columns: fixed + 3 custom ones\n",
    "final_labels = labels[:len(rows[0]) - 3] + ['parents', 'children', 'nPolySidesPolygonRays']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows, columns=final_labels)\n",
    "\n",
    "# Convert date and time columns to datetime\n",
    "df['date_utc'] = pd.to_datetime(\n",
    "    df['Year'].astype(str) + '-' +\n",
    "    df['Month'].astype(str).str.zfill(2) + '-' +\n",
    "    df['Day'].astype(str).str.zfill(2) + ' ' +\n",
    "    df['Hour'].astype(str).str.zfill(2) + ':' +\n",
    "    df['Min'].astype(str).str.zfill(2) + ':' +\n",
    "    df['Sec'].astype(str).str.zfill(2),\n",
    "    format='%Y-%m-%d %H:%M:%S',\n",
    "    utc=True\n",
    ")\n",
    "# Print df \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b847f47c-2481-475b-9b68-513e0a5dee8b",
   "metadata": {},
   "source": [
    "Let's explore the TITAN output now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dfadd0-c06c-4fc8-a899-e39c8b526d23",
   "metadata": {},
   "source": [
    "### How does TITAN work?\n",
    "\n",
    "TITAN identifies individual radar cells  within every radar volume , based on reflectivity and volume thresholds. Then, it tracks them through time using a combination and optimization scheme, and geometric logic to address splitting and merging storms. In this example, we have set the minimum reflectivity threshold to 35 dBZ. This is shown in column 'dBZThreshold'. That threshold defines the minimum reflectivity for our 'cell' entity.\n",
    "\n",
    "### What is the TITAN output?\n",
    "\n",
    "TITAN outputs cell fetures at each tracking timestep, and identifies cells within major systems, based on their interaction with neighboring cells. Therefore, each cell will have a simple and a complex identifier (“SimpleNum” and “ComplexNum”) in the TITAN output text file. For example, if we are tracking a multicell system, all the individual cells tracked within the major system will have different \"SimplNum\" identifiers, however, they will al have the same \"ComplexNum\" identifier (the main multicell system).\n",
    "\n",
    "Let's inspect our derecho case now! How many Complexes we can identify? Which one contains more tracks (e.g., single cell tracks, and split/merge processes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d4c5f-8406-443f-9ce0-38cc49bbad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique SimpleNum per ComplexNum\n",
    "simple_counts = df.groupby('ComplexNum')['SimpleNum'].nunique().reset_index(name='NumSimple')\n",
    "\n",
    "# Sort (optional, for better visuals)\n",
    "#simple_counts = simple_counts.sort_values(by='NumSimple', ascending=False)\n",
    "\n",
    "# Plot 1\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(y='ComplexNum', x='NumSimple', data=simple_counts, palette='Set3')\n",
    "plt.title('Number of SimpleNum per ComplexNum', fontsize=16)\n",
    "plt.xlabel('Count of Unique SimpleNum ID', fontsize=14)\n",
    "plt.ylabel('ComplexNum ID', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195291d6-af67-4560-8472-b009b6e9906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Filter dataframe for ComplexNum == 0 and sort by time\n",
    "df0 = df[df['ComplexNum'] == \"0\"].copy()\n",
    "df0 = df0.sort_values('date_utc')\n",
    "df0['MaxDBZ(dBZ)'] = pd.to_numeric(df0['MaxDBZ(dBZ)'], errors='coerce')\n",
    "df0['date_utc'] = pd.to_datetime(df0['date_utc'], errors='coerce', utc=True)\n",
    "\n",
    "#  Plot\n",
    "y_min = 30\n",
    "y_max = 70\n",
    "y_ticks = np.arange(y_min, y_max + 1, 5)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.lineplot(data=df0, x='date_utc', y='MaxDBZ(dBZ)', hue='SimpleNum', palette='gist_ncar')\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.yticks(y_ticks,fontsize=12)\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.title('MaxDBZ over Time for ComplexNum = 0', fontsize=16)\n",
    "plt.xlabel('Time (UTC)', fontsize=14)\n",
    "plt.ylabel('MaxDBZ (dBZ)',fontsize=14)\n",
    "# Remove legend\n",
    "plt.legend([], [], frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc1fdc-25e0-4648-add4-26ede0204fc2",
   "metadata": {},
   "source": [
    "Now we can also plot the centroids of each tracked cell, in a Cartopy map, and add circles around the centroid based on how big the cell volume is in each timestep. We will also show the different cells ('SimpleNum') in different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e9d0b-9daa-44ca-8c6c-71c4cfc571f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.sort_values(['SimpleNum', 'date_utc'])\n",
    "# Convert lat/lon columns to numeric, coercing errors to NaN\n",
    "df0['VolCentroidLat(deg)'] = pd.to_numeric(df0['VolCentroidLat(deg)'], errors='coerce')\n",
    "df0['VolCentroidLon(deg)'] = pd.to_numeric(df0['VolCentroidLon(deg)'], errors='coerce')\n",
    "\n",
    "# Set up map plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([-84, -76, 41, 46], crs=ccrs.PlateCarree()) \n",
    "ax.coastlines(resolution='10m')\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 14}\n",
    "gl.ylabel_style = {'size': 14}\n",
    "\n",
    "# Unique SimpleNum and colors\n",
    "simple_nums = df0['SimpleNum'].unique()\n",
    "palette = sns.color_palette(\"gist_ncar\", n_colors=len(simple_nums))\n",
    "df0['Volume(km3)'] = pd.to_numeric(df0['Volume(km3)'], errors='coerce').fillna(0)\n",
    "\n",
    "# We normalize the Volume for the marker sizes\n",
    "for i, simple_num in enumerate(simple_nums):\n",
    "    track = df0[df0['SimpleNum'] == simple_num].copy()\n",
    "\n",
    "    lat = track['VolCentroidLat(deg)']\n",
    "    lon = track['VolCentroidLon(deg)']\n",
    "    vol = pd.to_numeric(track['Volume(km3)'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Scale volume: use log scale to compress range + clip to reasonable range\n",
    "    sizes = np.log10(vol + 1) * 200  # +1 to avoid log(0)\n",
    "    #sizes = sizes.clip(10, 300)      \n",
    "\n",
    "    ax.plot(lon, lat, marker='o', linestyle='-', color=palette[i], alpha=0.7, transform=ccrs.PlateCarree())\n",
    "    ax.scatter(lon, lat, s=sizes, color=palette[i], alpha=0.5, transform=ccrs.PlateCarree(), edgecolor='k', linewidth=0.5)\n",
    "\n",
    "#plt.legend(title='SimpleNum', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.title('Tracks for ComplexNum = 0', fontsize= 16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504876c-d64e-43a7-ab7c-21332573e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Set the map extent (lon_min, lon_max, lat_min, lat_max)\n",
    "ax.set_extent([-84, -76, 42, 46], crs=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#color by time\n",
    "timesteps = df0['date_utc'].unique()\n",
    "palette = sns.color_palette(\"gist_ncar\", n_colors=len(timesteps))\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xlabel_style = {'size': 14}\n",
    "gl.ylabel_style = {'size': 14}\n",
    "\n",
    "for idx, row in df0.iterrows():\n",
    "    lat_centroid = float(row['EnvelopeCentroidLat(deg)'])\n",
    "    lon_centroid = float(row['EnvelopeCentroidLon(deg)'])\n",
    "    rays = row['nPolySidesPolygonRays']\n",
    "    \n",
    "    if not rays or len(rays) == 0:\n",
    "        continue  \n",
    "    \n",
    "    angles = np.deg2rad(np.arange(0, 360, 5))  # 72 vertices at every 5 degrees\n",
    "    rays = np.array(rays, dtype=float) #from centroid to vertex\n",
    "    \n",
    "    # Rays in km to degrees\n",
    "    ray_x = rays * np.cos(angles)\n",
    "    ray_y = rays * np.sin(angles)\n",
    "\n",
    "    # Approximate conversion from km to degrees lat/lon\n",
    "    lat_vertices = lat_centroid + ray_y / 111\n",
    "    lon_vertices = lon_centroid + ray_x / (111 * np.cos(np.deg2rad(lat_centroid)))\n",
    "\n",
    "    polygon_points = list(zip(lon_vertices, lat_vertices))\n",
    "    \n",
    "    poly = Polygon(polygon_points)\n",
    "    time_idx = np.where(timesteps == row['date_utc'])[0][0]\n",
    "\n",
    "    ax.add_geometries([poly], crs=ccrs.PlateCarree(),\n",
    "                      edgecolor=palette[time_idx], facecolor='none', linewidth=1)\n",
    "    \n",
    "    ax.plot(lon_centroid, lat_centroid, marker='o',color='grey', markersize=1.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Track Polygons for ComplexNum=0\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005b4e4-686b-45ac-b0bc-a3a49e36f5e6",
   "metadata": {},
   "source": [
    "# Afternoon Project\n",
    "\n",
    "To run TITAN on the hail case, the previous commands just need to be recreated using the hail parameter files. We've summarized the commands below.\n",
    "\n",
    "1. Convert the data.\n",
    "<code lang=\"bash\">!$LROSE_DIR/RadxConvert -sort_rays_by_time -const_ngates -params ./params/titan/RadxConvert.qc.hail -debug -f ${DATA_DIR}/radar/raw/hail/202408060*h5</code>\n",
    "\n",
    "2. Prepare the sounding data.\n",
    "<code lang=\"bash\">!$LROSE_DIR/Mdv2SoundingSpdb -debug -params ./params/titan/Mdv2SoundingSpdb.ERA5.hail -f $DATA_DIR/ERA5/20240806/20240806_0*</code>\n",
    "\n",
    "3. Run the PID.\n",
    "<code lang=\"bash\">!$LROSE_DIR/RadxPid -params ./params/titan/RadxPid.hail -debug</code>\n",
    "\n",
    "4. Grid the data on a Cartesian grid.\n",
    "<code lang=\"bash\">!$LROSE_DIR/Radx2Grid -params ./params/titan/Radx2Grid.hail -debug</code>\n",
    "\n",
    "5. Run TITAN.\n",
    "<code lang=\"bash\">!$LROSE_DIR/Titan -params ./params/titan/Titan.hail -start \"2024 08 06 00 00 00\" -end \"2024 08 06 06 00 00\" -debug</code>\n",
    "\n",
    "6. Convert the tracks to an ASCII file.\n",
    "<code lang=\"bash\">!$LROSE_DIR/Tracks2Ascii -params ./params/titan/Tracks2Ascii.hail -f ~/data/ams2025/titan/storms/Strathmore/20240806.th5 > $DATA_DIR/titan/ascii/Tracks2Ascii.hail.txt</code>\n",
    "\n",
    "7. Convert the output to NetCDF.\n",
    "<code lang=\"bash\">!$LROSE_DIR/Tstorms2NetCDF -params ./params/titan/Tstorms2NetCDF.hail -debug -f $DATA_DIR/titan/storms/Strathmore/20240806.sh5</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1737bb-5ead-4824-868c-59888220ec6b",
   "metadata": {},
   "source": [
    "### Play with the reflectivity or minimum area thresholds\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>File Task: modify parameters in text files.</b> \n",
    "\n",
    "If you're curious how the parameter choices affect the analysis, feel free to play around with different values of the reflectivity and minimum area thresholds.\n",
    "\n",
    "These are in the ./params/titan/Titan.hail and ./params/titan/Titan.derecho parameter files, which you can edit directly in JupyterLab.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7230a65e-65fa-4bc8-a52b-52f37335c2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
